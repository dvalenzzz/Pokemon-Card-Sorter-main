{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'imagehash'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_29192\\4289540399.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# import cardData\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mimagehash\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtimeit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'imagehash'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "# import cardData\n",
    "import imagehash\n",
    "import utils\n",
    "import timeit\n",
    "# import time\n",
    "from IPython.display import display, clear_output\n",
    "import PIL.Image\n",
    "import io\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\valen\\Downloads\\Pokemon-Card-Scanner-main\\Pokemon-Card-Scanner-main\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'utils' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_29192\\3393719033.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[0mimgWarpColored\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mblackImg\u001b[0m  \u001b[1;31m# Set imgWarpColored\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;31m# Get biggest contour\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m         \u001b[0mcorners\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxArea\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbiggestContour\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontours\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;31m# Initialize values for matching card and found to ensure loop works even though no values are found.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[0mmatchingCard\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mheightCard\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidthCard\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'utils' is not defined"
     ]
    }
   ],
   "source": [
    "widthCard = 330\n",
    "heightCard = 440\n",
    "cam = cv2.VideoCapture(1)\n",
    "background_subtractor = cv2.createBackgroundSubtractorMOG2(history=500, varThreshold=50, detectShadows=False)\n",
    "\n",
    "blackImg = np.zeros((heightCard, widthCard, 3), np.uint8)\n",
    "try:\n",
    "    while True:\n",
    "\n",
    "        check, frame = cam.read()\n",
    "\n",
    "        rot90frame = cv2.rotate(frame, cv2.ROTATE_90_CLOCKWISE)\n",
    "        # rot90frame = cv2.resize(rot90frame, (widthCard+50, heightCard+50))\n",
    "\n",
    "\n",
    "        # Make image gray scale\n",
    "        grayFrame = cv2.cvtColor(rot90frame, cv2.COLOR_BGR2GRAY)\n",
    "        # Blur the image to reduce noise\n",
    "        blurredFrame = cv2.GaussianBlur(grayFrame, (3, 3), 0)\n",
    "\n",
    "        # Background Remover \n",
    "\n",
    "        fg_mask = background_subtractor.apply(frame)\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "        fg_mask = cv2.morphologyEx(fg_mask, cv2.MORPH_OPEN, kernel)\n",
    "        # foreground = cv2.bitwise_and(blurredFrame, blurredFrame, mask=fg_mask)\n",
    "\n",
    "        # Use Canny edge detection to get edges\n",
    "        edgedFrame = cv2.Canny(fg_mask, threshold1=80, threshold2=150)\n",
    "        # edgedFrame = cv2.adaptiveThreshold(blurredFrame, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 303, 56)\n",
    "        # Clean up edges\n",
    "        kernel = np.ones((5,5))\n",
    "        frameDial = cv2.dilate(edgedFrame, kernel, iterations=2)\n",
    "        frameThreshold = cv2.erode(frameDial, kernel, iterations=1)\n",
    "\n",
    "        # Get image contours\n",
    "        contourFrame = rot90frame.copy()\n",
    "        bigContour = rot90frame.copy()\n",
    "        contours, hierarchy = cv2.findContours(edgedFrame, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        cv2.drawContours(contourFrame, contours, -1, (0, 255, 0), 10)\n",
    "\n",
    "        imgWarpColored = blackImg  # Set imgWarpColored\n",
    "        # Get biggest contour\n",
    "        corners, maxArea = utils.biggestContour(contours)\n",
    "        # Initialize values for matching card and found to ensure loop works even though no values are found. \n",
    "        matchingCard = np.zeros((heightCard, widthCard, 3), dtype=np.uint8)\n",
    "        found = False #\n",
    "        cardinfo = 0\n",
    "        if len(corners) == 4:\n",
    "            corners = [corners[0][0], corners[1][0], corners[2][0], corners[3][0]]\n",
    "            corners = utils.reorderCorners(corners)  # Reorders corners to [topLeft, topRight, bottomLeft, bottomRight]\n",
    "            #cv2.drawContours(bigContour, corners, -1, (0, 255, 0), 10)\n",
    "            bigContour = utils.drawRectangle(bigContour, corners)\n",
    "            pts1 = np.float32(corners)\n",
    "            pts2 = np.float32([[0, 0], [widthCard, 0], [0, heightCard], [widthCard, heightCard]])\n",
    "            # Makes a matrix that transforms the detected card to a vertical rectangle\n",
    "            matrix = cv2.getPerspectiveTransform(pts1, pts2)\n",
    "            # Transforms card to a rectangle widthCard x heightCard\n",
    "            imgWarpColored = cv2.warpPerspective(rot90frame, matrix, (widthCard, heightCard))\n",
    "            section_start = timeit.default_timer()\n",
    "            # Check if a matching card has been found, and if so, display it\n",
    "            found, matchingCard, cardinfo = utils.findCard(imgWarpColored.copy())  # Check to see if a matching card was found\n",
    "            section_end = timeit.default_timer()            \n",
    "\n",
    "        # Resize all of the images to the same dimensions\n",
    "        # Note: imgWarpColored is already resized and matchingCard gets resized in utils.getMatchingCard()\n",
    "        rot90frame = cv2.resize(rot90frame, (widthCard, heightCard))\n",
    "        grayFrame = cv2.resize(grayFrame, (widthCard, heightCard))\n",
    "        blurredFrame = cv2.resize(blurredFrame, (widthCard, heightCard))\n",
    "        edgedFrame = cv2.resize(edgedFrame, (widthCard, heightCard))\n",
    "        contourFrame = cv2.resize(contourFrame, (widthCard, heightCard))\n",
    "        bigContour = cv2.resize(bigContour, (widthCard, heightCard))\n",
    "        fg_mask = cv2.resize(fg_mask, (widthCard, heightCard))\n",
    "\n",
    "        # print(f\"Time to read and rotate image: {section_end - section_start:.4f} seconds\")\n",
    "\n",
    "        # An array of all 8 images\n",
    "        imageArr = ([rot90frame, grayFrame, blurredFrame, edgedFrame],\n",
    "                    [contourFrame, bigContour, imgWarpColored, fg_mask])\n",
    "\n",
    "        # Labels for each image\n",
    "        labels = [[\"Original\", \"Gray\", \"Blurred\", \"Threshold\"],\n",
    "                    [\"Contours\", \"Biggest Contour\", \"Warped Perspective\", \"foreground\"]]\n",
    "\n",
    "        # Stack all 8 images into one and add text labels\n",
    "        stackedImage = utils.makeDisplayImage(imageArr, labels)\n",
    "        imageArr = cv2.cvtColor(stackedImage, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Convert the frame to an image format compatible with Jupyter\n",
    "        pil_im = PIL.Image.fromarray(imageArr)\n",
    "        buf = io.BytesIO()\n",
    "        pil_im.save(buf, format='JPEG')\n",
    "        \n",
    "        # Display the frame in Jupyter Notebook\n",
    "        clear_output(wait=True)\n",
    "        display(PIL.Image.open(buf))\n",
    "        # Display the image\n",
    "except KeyboardInterrupt:\n",
    "    # This allows you to stop the loop with an interrupt\n",
    "    print(\"Stopped by user\")\n",
    "finally:\n",
    "    # Release the camera and close any open windows\n",
    "    cam.release()\n",
    "    cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopped by user\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from IPython.display import display, clear_output\n",
    "import PIL.Image\n",
    "import io\n",
    "\n",
    "# Open the video capture\n",
    "cam = cv2.VideoCapture(0)  # Change the argument to 1 if using an external camera\n",
    "\n",
    "# Set desired width and height\n",
    "widthCard = 330\n",
    "heightCard = 440\n",
    "cam.set(cv2.CAP_PROP_FRAME_WIDTH, widthCard)\n",
    "cam.set(cv2.CAP_PROP_FRAME_HEIGHT, heightCard)\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        # Capture a frame from the camera\n",
    "        check, frame = cam.read()\n",
    "        if not check:\n",
    "            print(\"Failed to capture image\")\n",
    "            break\n",
    "\n",
    "        # Rotate and resize frame if needed\n",
    "        frame = cv2.rotate(frame, cv2.ROTATE_90_CLOCKWISE)\n",
    "        frame = cv2.resize(frame, (widthCard, heightCard))\n",
    "\n",
    "        # Convert to RGB format for display in Jupyter\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Convert the frame to an image format compatible with Jupyter\n",
    "        pil_im = PIL.Image.fromarray(rgb_frame)\n",
    "        buf = io.BytesIO()\n",
    "        pil_im.save(buf, format='JPEG')\n",
    "        \n",
    "        # Display the frame in Jupyter Notebook\n",
    "        clear_output(wait=True)\n",
    "        display(PIL.Image.open(buf))\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    # This allows you to stop the loop with an interrupt\n",
    "    print(\"Stopped by user\")\n",
    "finally:\n",
    "    # Release the camera and close any open windows\n",
    "    cam.release()\n",
    "    cv2.destroyAllWindows() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopped by user\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "widthCard = 330\n",
    "heightCard = 440\n",
    "cam = cv2.VideoCapture(1)\n",
    "background_subtractor = cv2.createBackgroundSubtractorMOG2(history=500, varThreshold=50, detectShadows=False)\n",
    "\n",
    "blackImg = np.zeros((heightCard, widthCard, 3), np.uint8)\n",
    "try:\n",
    "    while True:\n",
    "        check, frame = cam.read()\n",
    "        if not check:\n",
    "            print(\"Camera feed not detected.\")\n",
    "            break\n",
    "\n",
    "        # Rotate the frame to get the correct orientation\n",
    "        rot90frame = cv2.rotate(frame, cv2.ROTATE_90_CLOCKWISE)\n",
    "        \n",
    "        # Make the image grayscale\n",
    "        grayFrame = cv2.cvtColor(rot90frame, cv2.COLOR_BGR2GRAY)\n",
    "        blurredFrame = cv2.GaussianBlur(grayFrame, (3, 3), 0)\n",
    "\n",
    "        # Apply background subtraction\n",
    "        fg_mask = background_subtractor.apply(rot90frame)\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "        fg_mask = cv2.morphologyEx(fg_mask, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "        # Edge detection\n",
    "        edgedFrame = cv2.Canny(fg_mask, threshold1=80, threshold2=150)\n",
    "        kernel = np.ones((5,5))\n",
    "        frameDial = cv2.dilate(edgedFrame, kernel, iterations=2)\n",
    "        frameThreshold = cv2.erode(frameDial, kernel, iterations=1)\n",
    "\n",
    "        # Find contours\n",
    "        contours, _ = cv2.findContours(edgedFrame, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        contourFrame = rot90frame.copy()\n",
    "        cv2.drawContours(contourFrame, contours, -1, (0, 255, 0), 10)\n",
    "\n",
    "        # Process biggest contour for card\n",
    "        corners, maxArea = utils.biggestContour(contours)\n",
    "        matchingCard = np.zeros((heightCard, widthCard, 3), dtype=np.uint8)\n",
    "        found, cardinfo = False, 0\n",
    "        imgWarpColored = blackImg\n",
    "\n",
    "        if len(corners) == 4:\n",
    "            corners = utils.reorderCorners([corners[i][0] for i in range(4)])\n",
    "            bigContour = utils.drawRectangle(rot90frame.copy(), corners)\n",
    "            pts1 = np.float32(corners)\n",
    "            pts2 = np.float32([[0, 0], [widthCard, 0], [0, heightCard], [widthCard, heightCard]])\n",
    "            matrix = cv2.getPerspectiveTransform(pts1, pts2)\n",
    "            imgWarpColored = cv2.warpPerspective(rot90frame, matrix, (widthCard, heightCard))\n",
    "            found, matchingCard, cardinfo = utils.findCard(imgWarpColored.copy())\n",
    "\n",
    "        # Resize frames for display\n",
    "        rot90frame = cv2.resize(rot90frame, (widthCard, heightCard))\n",
    "        grayFrame = cv2.resize(grayFrame, (widthCard, heightCard))\n",
    "        blurredFrame = cv2.resize(blurredFrame, (widthCard, heightCard))\n",
    "        edgedFrame = cv2.resize(edgedFrame, (widthCard, heightCard))\n",
    "        contourFrame = cv2.resize(contourFrame, (widthCard, heightCard))\n",
    "        bigContour = cv2.resize(bigContour, (widthCard, heightCard)) if 'bigContour' in locals() else blackImg\n",
    "        fg_mask = cv2.resize(fg_mask, (widthCard, heightCard))\n",
    "\n",
    "        # Stack and display images in Jupyter Notebook\n",
    "        imageArr = ([rot90frame, grayFrame, blurredFrame, edgedFrame],\n",
    "                    [contourFrame, bigContour, imgWarpColored, fg_mask])\n",
    "        labels = [[\"Original\", \"Gray\", \"Blurred\", \"Threshold\"],\n",
    "                  [\"Contours\", \"Biggest Contour\", \"Warped Perspective\", \"Foreground Mask\"]]\n",
    "        \n",
    "        stackedImage = utils.makeDisplayImage(imageArr, labels)\n",
    "        stackedImage = cv2.cvtColor(stackedImage, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Convert and display\n",
    "        pil_im = PIL.Image.fromarray(stackedImage)\n",
    "        buf = io.BytesIO()\n",
    "        pil_im.save(buf, format='JPEG')\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        display(PIL.Image.open(buf))\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Stopped by user\")\n",
    "finally:\n",
    "    cam.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'utils' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_29192\\3460401531.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m         \u001b[1;31m# Assuming utils.makeDisplayImage creates a labeled display image; otherwise, you can replace it\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m         \u001b[0mstackedImage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmakeDisplayImage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimageArr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m         \u001b[0mstackedImage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstackedImage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'utils' is not defined"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import timeit\n",
    "from IPython.display import display, clear_output\n",
    "import PIL.Image\n",
    "import io\n",
    "\n",
    "widthCard = 330\n",
    "heightCard = 440\n",
    "cam = cv2.VideoCapture(1)\n",
    "background_subtractor = cv2.createBackgroundSubtractorMOG2(history=500, varThreshold=50, detectShadows=False)\n",
    "\n",
    "blackImg = np.zeros((heightCard, widthCard, 3), np.uint8)\n",
    "\n",
    "def biggestContour(contours, min_area=10000):\n",
    "    largest = None\n",
    "    max_area = 0\n",
    "    approx_corners = []\n",
    "\n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        if area > min_area:  # Only consider contours with area larger than min_area\n",
    "            perimeter = cv2.arcLength(contour, True)\n",
    "            approx = cv2.approxPolyDP(contour, 0.02 * perimeter, True)\n",
    "\n",
    "            if len(approx) == 4 and area > max_area:\n",
    "                largest = contour\n",
    "                max_area = area\n",
    "                approx_corners = approx\n",
    "\n",
    "    return approx_corners, max_area\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        check, frame = cam.read()\n",
    "        if not check:\n",
    "            print(\"Camera feed not detected.\")\n",
    "            break\n",
    "\n",
    "        # Rotate the frame to get the correct orientation\n",
    "        rot90frame = cv2.rotate(frame, cv2.ROTATE_90_CLOCKWISE)\n",
    "        \n",
    "        # Make the image grayscale\n",
    "        grayFrame = cv2.cvtColor(rot90frame, cv2.COLOR_BGR2GRAY)\n",
    "        blurredFrame = cv2.GaussianBlur(grayFrame, (3, 3), 0)\n",
    "\n",
    "        # Apply background subtraction\n",
    "        fg_mask = background_subtractor.apply(rot90frame)\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "        fg_mask = cv2.morphologyEx(fg_mask, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "        # Edge detection\n",
    "        edgedFrame = cv2.Canny(fg_mask, threshold1=80, threshold2=150)\n",
    "        kernel = np.ones((5,5))\n",
    "        frameDial = cv2.dilate(edgedFrame, kernel, iterations=2)\n",
    "        frameThreshold = cv2.erode(frameDial, kernel, iterations=1)\n",
    "\n",
    "        # Find contours\n",
    "        contours, _ = cv2.findContours(edgedFrame, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        contourFrame = rot90frame.copy()\n",
    "        cv2.drawContours(contourFrame, contours, -1, (0, 255, 0), 10)\n",
    "\n",
    "        # Process biggest contour for card\n",
    "        corners, maxArea = biggestContour(contours)\n",
    "        matchingCard = np.zeros((heightCard, widthCard, 3), dtype=np.uint8)\n",
    "        found, cardinfo = False, 0\n",
    "        imgWarpColored = blackImg\n",
    "\n",
    "        if len(corners) == 4:\n",
    "            corners = [corners[i][0] for i in range(4)]\n",
    "            bigContour = rot90frame.copy()\n",
    "            cv2.drawContours(bigContour, [np.array(corners)], -1, (0, 255, 0), 10)\n",
    "            pts1 = np.float32(corners)\n",
    "            pts2 = np.float32([[0, 0], [widthCard, 0], [0, heightCard], [widthCard, heightCard]])\n",
    "            matrix = cv2.getPerspectiveTransform(pts1, pts2)\n",
    "            imgWarpColored = cv2.warpPerspective(rot90frame, matrix, (widthCard, heightCard))\n",
    "            \n",
    "            # Assuming utils.findCard is a function that finds the card match, you may keep this line if needed\n",
    "            # found, matchingCard, cardinfo = utils.findCard(imgWarpColored.copy())\n",
    "\n",
    "        # Resize frames for display\n",
    "        rot90frame = cv2.resize(rot90frame, (widthCard, heightCard))\n",
    "        grayFrame = cv2.resize(grayFrame, (widthCard, heightCard))\n",
    "        blurredFrame = cv2.resize(blurredFrame, (widthCard, heightCard))\n",
    "        edgedFrame = cv2.resize(edgedFrame, (widthCard, heightCard))\n",
    "        contourFrame = cv2.resize(contourFrame, (widthCard, heightCard))\n",
    "        bigContour = cv2.resize(bigContour, (widthCard, heightCard)) if 'bigContour' in locals() else blackImg\n",
    "        fg_mask = cv2.resize(fg_mask, (widthCard, heightCard))\n",
    "\n",
    "        # Stack and display images in Jupyter Notebook\n",
    "        imageArr = ([rot90frame, grayFrame, blurredFrame, edgedFrame],\n",
    "                    [contourFrame, bigContour, imgWarpColored, fg_mask])\n",
    "        labels = [[\"Original\", \"Gray\", \"Blurred\", \"Threshold\"],\n",
    "                  [\"Contours\", \"Biggest Contour\", \"Warped Perspective\", \"Foreground Mask\"]]\n",
    "        \n",
    "        # Assuming utils.makeDisplayImage creates a labeled display image; otherwise, you can replace it\n",
    "        stackedImage = utils.makeDisplayImage(imageArr, labels)\n",
    "        stackedImage = cv2.cvtColor(stackedImage, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Convert and display\n",
    "        pil_im = PIL.Image.fromarray(stackedImage)\n",
    "        buf = io.BytesIO()\n",
    "        pil_im.save(buf, format='JPEG')\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        display(PIL.Image.open(buf))\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Stopped by user\")\n",
    "finally:\n",
    "    cam.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
