{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\valen\\Downloads\\Pokemon-Card-Scanner-main\\Pokemon-Card-Scanner-main\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "# import timeit\n",
    "from IPython.display import display, clear_output\n",
    "import PIL.Image\n",
    "import io\n",
    "import utils\n",
    "\n",
    "widthCard = 330\n",
    "heightCard = 440\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopped by user\n"
     ]
    }
   ],
   "source": [
    "cam = cv2.VideoCapture(1)\n",
    "# background_subtractor = cv2.createBackgroundSubtractorMOG2(history=500, \n",
    "#                                        \n",
    "# cv2.namedWindow(\"Canny Tuner\", cv2.WINDOW_NORMAL)\n",
    "# cv2.resizeWindow(\"Canny Tuner\", 400, 100)\n",
    "# cv2.createTrackbar(\"Threshold1\", \"Canny Tuner\", 0, 150, lambda x: None)\n",
    "# cv2.createTrackbar(\"Threshold2\", \"Canny Tuner\", 150, 500, lambda x: None)\n",
    "\n",
    "\n",
    "blackImg = np.zeros((heightCard, widthCard, 3), np.uint8)\n",
    "\n",
    "def biggestContour(contours, min_area=5000): ###10000 might be too large?\n",
    "    largest = None\n",
    "    max_area = 0\n",
    "    approx_corners = []\n",
    "\n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        if area > min_area:  # Only consider contours with area larger than min_area\n",
    "            perimeter = cv2.arcLength(contour, True)\n",
    "            approx = cv2.approxPolyDP(contour, 0.02 * perimeter, True)\n",
    "\n",
    "            if len(approx) == 4 and area > max_area:\n",
    "                largest = contour\n",
    "                max_area = area\n",
    "                approx_corners = approx\n",
    "\n",
    "    return approx_corners, max_area\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        check, frame = cam.read()\n",
    "        if not check:\n",
    "            print(\"Camera feed not detected.\")\n",
    "            break\n",
    "\n",
    "        # Rotate the frame to get the correct orientation\n",
    "        rot90frame = cv2.rotate(frame, cv2.ROTATE_90_CLOCKWISE)\n",
    "        rot90frame = cv2.rotate(rot90frame, cv2.ROTATE_180)        # Make the image grayscale\n",
    "        grayFrame = cv2.cvtColor(rot90frame, cv2.COLOR_BGR2GRAY)\n",
    "        blurredFrame = cv2.GaussianBlur(grayFrame, (3, 3), 0)\n",
    "\n",
    "        # Apply background subtraction\n",
    "        # fg_mask = background_subtractor.apply(blurredFrame)#!!!!!\n",
    "        # kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "        # fg_mask = cv2.morphologyEx(fg_mask, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "\n",
    "        # thresh1 = input()\n",
    "        # thresh2 = input()\n",
    "    \n",
    "        # Edge detection\n",
    "        edgedFrame = cv2.Canny(blurredFrame, 120, 255)\n",
    "        kernel = np.ones((1,1))\n",
    "        frameDial = cv2.dilate(edgedFrame, kernel, iterations=1)\n",
    "        frameThreshold = cv2.erode(frameDial, kernel, iterations=1)\n",
    "\n",
    "        # Find contours\n",
    "        contours, _ = cv2.findContours(frameThreshold, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        contourFrame = rot90frame.copy()\n",
    "        cv2.drawContours(contourFrame, contours, -1, (0, 255, 0), 10)\n",
    "\n",
    "        # Process biggest contour for card\n",
    "        corners, maxArea = biggestContour(contours)\n",
    "        matchingCard = np.zeros((heightCard, widthCard, 3), dtype=np.uint8)\n",
    "        found, cardinfo = False, 0\n",
    "        imgWarpColored = blackImg\n",
    "\n",
    "        if len(corners) == 4:\n",
    "            corners = [corners[i][0] for i in range(4)]\n",
    "            bigContour = rot90frame.copy()\n",
    "            cv2.drawContours(bigContour, [np.array(corners)], -1, (255, 0, 0), 10)\n",
    "            pts1 = np.float32(corners)\n",
    "            pts2 = np.float32([[0, 0], [widthCard, 0], [0, heightCard], [widthCard, heightCard]])\n",
    "            matrix = cv2.getPerspectiveTransform(pts1, pts2)\n",
    "            imgWarpColored = cv2.warpPerspective(rot90frame, matrix, (widthCard, heightCard))\n",
    "            \n",
    "            # Assuming utils.findCard is a function that finds the card match, you may keep this line if needed\n",
    "            # found, matchingCard, cardinfo = utils.findCard(imgWarpColored.copy())\n",
    "\n",
    "        # Resize frames for display\n",
    "        rot90frame = cv2.resize(rot90frame, (widthCard, heightCard))\n",
    "        grayFrame = cv2.resize(grayFrame, (widthCard, heightCard))\n",
    "        blurredFrame = cv2.resize(blurredFrame, (widthCard, heightCard))\n",
    "        edgedFrame = cv2.resize(edgedFrame, (widthCard, heightCard))\n",
    "        contourFrame = cv2.resize(contourFrame, (widthCard, heightCard))\n",
    "        bigContour = cv2.resize(bigContour, (widthCard, heightCard)) if 'bigContour' in locals() else blackImg\n",
    "        # fg_mask = cv2.resize(fg_mask, (widthCard, heightCard))\n",
    "\n",
    "        # Stack and display images in Jupyter Notebook\n",
    "        imageArr = ([rot90frame, grayFrame, blurredFrame, edgedFrame],\n",
    "                    [contourFrame, bigContour, imgWarpColored, rot90frame])\n",
    "        labels = [[\"Original\", \"Gray\", \"Blurred\", \"Threshold\"],\n",
    "                  [\"Contours\", \"Biggest Contour\", \"Warped Perspective\", \"OG\"]]\n",
    "        \n",
    "        # Assuming utils.makeDisplayImage creates a labeled display image; otherwise, you can replace it\n",
    "        stackedImage = utils.makeDisplayImage(imageArr, labels)\n",
    "        stackedImage = cv2.cvtColor(stackedImage, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Convert and display\n",
    "        pil_im = PIL.Image.fromarray(stackedImage)\n",
    "        buf = io.BytesIO()\n",
    "        pil_im.save(buf, format='JPEG')\n",
    "        k = cv2.waitKey(1) & 0xFF\n",
    "        if k==27:\n",
    "            break\n",
    "        clear_output(wait=True)\n",
    "        display(PIL.Image.open(buf))\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Stopped by user\")\n",
    "finally:\n",
    "    cam.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 43\u001b[0m\n\u001b[0;32m     40\u001b[0m blackImg \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((heightCard, widthCard, \u001b[38;5;241m3\u001b[39m), np\u001b[38;5;241m.\u001b[39muint8)\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# Make image gray scale\u001b[39;00m\n\u001b[1;32m---> 43\u001b[0m grayFrame \u001b[38;5;241m=\u001b[39m  \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcvtColor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrot90frame\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOLOR_BGR2GRAY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Blur the image to reduce noise\u001b[39;00m\n\u001b[0;32m     45\u001b[0m blurredFrame \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mGaussianBlur(grayFrame, (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m), \u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "# import timeit\n",
    "from IPython.display import display, clear_output\n",
    "import PIL.Image\n",
    "import io\n",
    "import utils\n",
    "\n",
    "widthCard = 330\n",
    "heightCard = 440\n",
    "cam = cv2.VideoCapture(1)\n",
    "background_subtractor = cv2.createBackgroundSubtractorMOG2(history=500, \n",
    "                                                           varThreshold=20, detectShadows=False)\n",
    "\n",
    "blackImg = np.zeros((heightCard, widthCard, 3), np.uint8)\n",
    "\n",
    "def biggestContour(contours, min_area=100000): ###10000 might be too large?\n",
    "    largest = None\n",
    "    max_area = 0\n",
    "    approx_corners = []\n",
    "\n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        if area > min_area:  # Only consider contours with area larger than min_area\n",
    "            perimeter = cv2.arcLength(contour, True)\n",
    "            approx = cv2.approxPolyDP(contour, 0.02 * perimeter, True)\n",
    "\n",
    "            if len(approx) == 4 and area > max_area:\n",
    "                largest = contour\n",
    "                max_area = area\n",
    "                approx_corners = approx\n",
    "\n",
    "    return approx_corners, max_area\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        check, frame = cam.read()\n",
    "        rot90frame = cv2.rotate(frame, cv2.ROTATE_90_CLOCKWISE)\n",
    "        # Create a blank image\n",
    "        blackImg = np.zeros((heightCard, widthCard, 3), np.uint8)\n",
    "\n",
    "        # Make image gray scale\n",
    "        grayFrame =  cv2.cvtColor(rot90frame, cv2.COLOR_BGR2GRAY)\n",
    "        # Blur the image to reduce noise\n",
    "        blurredFrame = cv2.GaussianBlur(grayFrame, (3, 3), 0)\n",
    "\n",
    "        # # Background Remover \n",
    "        # background_subtractor = cv2.createBackgroundSubtractorMOG2(history=500, varThreshold=50, detectShadows=False)\n",
    "        \n",
    "        # fg_mask = background_subtractor.apply(blurredFrame)\n",
    "        # foreground = cv2.bitwise_and(blurredFrame, blurredFrame, mask=fg_mask)\n",
    "\n",
    "        # Use Canny edge detection to get edges\n",
    "        edgedFrame = cv2.Canny(blurredFrame, threshold1=80, threshold2=150)\n",
    "        # edgedFrame = cv2.adaptiveThreshold(blurredFrame, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 303, 56)\n",
    "        # Clean up edges\n",
    "        kernel = np.ones((5,5))\n",
    "        frameDial = cv2.dilate(edgedFrame, kernel, iterations=2)\n",
    "        frameThreshold = cv2.erode(frameDial, kernel, iterations=1)\n",
    "\n",
    "        # Get image contours\n",
    "        contourFrame = rot90frame.copy()\n",
    "        bigContour = rot90frame.copy()\n",
    "        contours, hierarchy = cv2.findContours(edgedFrame, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        cv2.drawContours(contourFrame, contours, -1, (0, 255, 0), 10)\n",
    "\n",
    "        imgWarpColored = blackImg  # Set imgWarpColored\n",
    "        # Get biggest contour\n",
    "        corners, maxArea = utils.biggestContour(contours)\n",
    "        # Initialize values for matching card and found to ensure loop works even though no values are found. \n",
    "        matchingCard = np.zeros((heightCard, widthCard, 3), dtype=np.uint8)\n",
    "        found = False #\n",
    "        cardinfo = 0\n",
    "        if len(corners) == 4:\n",
    "            corners = [corners[0][0], corners[1][0], corners[2][0], corners[3][0]]\n",
    "            corners = utils.reorderCorners(corners)  # Reorders corners to [topLeft, topRight, bottomLeft, bottomRight]\n",
    "            #cv2.drawContours(bigContour, corners, -1, (0, 255, 0), 10)\n",
    "            bigContour = utils.drawRectangle(bigContour, corners)\n",
    "            pts1 = np.float32(corners)\n",
    "            pts2 = np.float32([[0, 0], [widthCard, 0], [0, heightCard], [widthCard, heightCard]])\n",
    "            # Makes a matrix that transforms the detected card to a vertical rectangle\n",
    "            matrix = cv2.getPerspectiveTransform(pts1, pts2)\n",
    "            # Transforms card to a rectangle widthCard x heightCard\n",
    "            imgWarpColored = cv2.warpPerspective(rot90frame, matrix, (widthCard, heightCard))\n",
    "            section_start = timeit.default_timer()\n",
    "            # Check if a matching card has been found, and if so, display it\n",
    "            found, matchingCard, cardinfo = utils.findCard(imgWarpColored.copy())  # Check to see if a matching card was found\n",
    "            section_end = timeit.default_timer()            \n",
    "\n",
    "        # Resize all of the images to the same dimensions\n",
    "        # Note: imgWarpColored is already resized and matchingCard gets resized in utils.getMatchingCard()\n",
    "        rot90frame = cv2.resize(rot90frame, (widthCard, heightCard))\n",
    "        grayFrame = cv2.resize(grayFrame, (widthCard, heightCard))\n",
    "        blurredFrame = cv2.resize(blurredFrame, (widthCard, heightCard))\n",
    "        edgedFrame = cv2.resize(edgedFrame, (widthCard, heightCard))\n",
    "        contourFrame = cv2.resize(contourFrame, (widthCard, heightCard))\n",
    "        bigContour = cv2.resize(bigContour, (widthCard, heightCard))\n",
    "        \n",
    "\n",
    "        # print(f\"Time to read and rotate image: {section_end - section_start:.4f} seconds\")\n",
    "\n",
    "        # An array of all 8 images\n",
    "        imageArr = ([rot90frame, grayFrame, blurredFrame, edgedFrame],\n",
    "                    [contourFrame, bigContour, imgWarpColored, matchingCard])\n",
    "\n",
    "        # Labels for each image\n",
    "        labels = [[\"Original\", \"Gray\", \"Blurred\", \"Threshold\"],\n",
    "                  [\"Contours\", \"Biggest Contour\", \"Warped Perspective\", \"Matching Card\"]]\n",
    "\n",
    "        # Stack all 8 images into one and add text labels\n",
    "        stackedImage = utils.makeDisplayImage(imageArr, labels)\n",
    "        # Convert and display\n",
    "        pil_im = PIL.Image.fromarray(stackedImage)\n",
    "        buf = io.BytesIO()\n",
    "        pil_im.save(buf, format='JPEG')\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        display(PIL.Image.open(buf))\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Stopped by user\")\n",
    "finally:\n",
    "    cam.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valen\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 1920 and the array at index 2 has size 1320",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 98\u001b[0m\n\u001b[0;32m     95\u001b[0m labels \u001b[38;5;241m=\u001b[39m [[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContours\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBiggest Contour\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWarped Perspective\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMatching Card\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[0;32m     97\u001b[0m \u001b[38;5;66;03m# Stack all 8 images into one and add text labels\u001b[39;00m\n\u001b[1;32m---> 98\u001b[0m stackedImage \u001b[38;5;241m=\u001b[39m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmakeDisplayImage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimageArr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;66;03m# Convert and display\u001b[39;00m\n\u001b[0;32m    100\u001b[0m pil_im \u001b[38;5;241m=\u001b[39m PIL\u001b[38;5;241m.\u001b[39mImage\u001b[38;5;241m.\u001b[39mfromarray(stackedImage)\n",
      "File \u001b[1;32mc:\\Users\\valen\\Downloads\\Pokemon-Card-Scanner-main\\Pokemon-Card-Scanner-main\\utils.py:272\u001b[0m, in \u001b[0;36mmakeDisplayImage\u001b[1;34m(imageArr, labels)\u001b[0m\n\u001b[0;32m    270\u001b[0m imageArr \u001b[38;5;241m=\u001b[39m [[ensure_3_channels(img) \u001b[38;5;28;01mfor\u001b[39;00m img \u001b[38;5;129;01min\u001b[39;00m row] \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m imageArr]\n\u001b[0;32m    271\u001b[0m hor \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mhstack(row) \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m imageArr]\n\u001b[1;32m--> 272\u001b[0m stacked \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;66;03m# Add labels, if required\u001b[39;00m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m stacked\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\numpy\\_core\\shape_base.py:291\u001b[0m, in \u001b[0;36mvstack\u001b[1;34m(tup, dtype, casting)\u001b[0m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arrs, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    290\u001b[0m     arrs \u001b[38;5;241m=\u001b[39m (arrs,)\n\u001b[1;32m--> 291\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_nx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcasting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcasting\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 1920 and the array at index 2 has size 1320"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "# import timeit\n",
    "from IPython.display import display, clear_output\n",
    "import PIL.Image\n",
    "import io\n",
    "import utils\n",
    "\n",
    "widthCard = 330\n",
    "heightCard = 440\n",
    "cam = cv2.VideoCapture(1)\n",
    "background_subtractor = cv2.createBackgroundSubtractorMOG2(history=500, \n",
    "                                                           varThreshold=20, detectShadows=False)\n",
    "\n",
    "blackImg = np.zeros((heightCard, widthCard, 3), np.uint8)\n",
    "\n",
    "def biggestContour(contours, min_area=100000): ###10000 might be too large?\n",
    "    largest = None\n",
    "    max_area = 0\n",
    "    approx_corners = []\n",
    "\n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        if area > min_area:  # Only consider contours with area larger than min_area\n",
    "            perimeter = cv2.arcLength(contour, True)\n",
    "            approx = cv2.approxPolyDP(contour, 0.02 * perimeter, True)\n",
    "\n",
    "            if len(approx) == 4 and area > max_area:\n",
    "                largest = contour\n",
    "                max_area = area\n",
    "                approx_corners = approx\n",
    "\n",
    "    return approx_corners, max_area\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        check, frame = cam.read()\n",
    "        if not check:\n",
    "            break\n",
    "        \n",
    "        rot90frame = cv2.rotate(frame, cv2.ROTATE_90_CLOCKWISE)\n",
    "        grayFrame = cv2.cvtColor(rot90frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Adaptive Histogram Equalization for contrast enhancement\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "        enhancedGray = clahe.apply(grayFrame)\n",
    "        \n",
    "        # Gaussian Blur to reduce noise\n",
    "        blurredFrame = cv2.GaussianBlur(enhancedGray, (7, 7), 0)\n",
    "\n",
    "        # Background Subtraction\n",
    "        fg_mask = background_subtractor.apply(blurredFrame)\n",
    "        foreground = cv2.bitwise_and(blurredFrame, blurredFrame, mask=fg_mask)\n",
    "\n",
    "        # Edge Detection (Canny)\n",
    "        edgedFrame = cv2.Canny(foreground, threshold1=50, threshold2=150)\n",
    "        \n",
    "        # Morphological Operations for cleaner edges\n",
    "        kernel = np.ones((5, 5))\n",
    "        frameDial = cv2.dilate(edgedFrame, kernel, iterations=2)\n",
    "        frameThreshold = cv2.erode(frameDial, kernel, iterations=1)\n",
    "\n",
    "        # Contour Detection\n",
    "        contours, _ = cv2.findContours(frameThreshold, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        contourFrame = rot90frame.copy()\n",
    "\n",
    "        # Find the biggest contour\n",
    "        corners, maxArea = biggestContour(contours, min_area=5000)  # Adjust min_area as needed\n",
    "\n",
    "        if len(corners) == 4:\n",
    "            corners = [corners[0][0], corners[1][0], corners[2][0], corners[3][0]]\n",
    "            corners = utils.reorderCorners(corners)\n",
    "            bigContour = utils.drawRectangle(contourFrame, corners)\n",
    "            pts1 = np.float32(corners)\n",
    "            pts2 = np.float32([[0, 0], [widthCard, 0], [0, heightCard], [widthCard, heightCard]])\n",
    "\n",
    "            # Perspective Transform\n",
    "            matrix = cv2.getPerspectiveTransform(pts1, pts2)\n",
    "            imgWarpColored = cv2.warpPerspective(rot90frame, matrix, (widthCard, heightCard))\n",
    "\n",
    "            # Match the card\n",
    "            found, matchingCard, cardinfo = utils.findCard(imgWarpColored.copy())\n",
    "\n",
    "        else:\n",
    "            bigContour = rot90frame.copy()  # If no contour is found, show original frame\n",
    "\n",
    "        # Display results (resize images as needed)\n",
    "        cv2.imshow(\"Contours\", bigContour)\n",
    "        cv2.imshow(\"Warped\", imgWarpColored)\n",
    "\n",
    "        # An array of all 8 images\n",
    "        imageArr = ([contourFrame, bigContour, imgWarpColored, matchingCard])\n",
    "\n",
    "        # Labels for each image\n",
    "        labels = [[\"Contours\", \"Biggest Contour\", \"Warped Perspective\", \"Matching Card\"]]\n",
    "\n",
    "        # Stack all 8 images into one and add text labels\n",
    "        stackedImage = utils.makeDisplayImage(imageArr, labels)\n",
    "        # Convert and display\n",
    "        pil_im = PIL.Image.fromarray(stackedImage)\n",
    "        buf = io.BytesIO()\n",
    "        pil_im.save(buf, format='JPEG')\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        display(PIL.Image.open(buf))\n",
    "\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Stopped by user\")\n",
    "finally:\n",
    "    cam.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ChatGPT Attempt to fix bg stuff\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
